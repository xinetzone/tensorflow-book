{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "source": [
        "````{admonition} Copyright 2020 The TensorFlow Authors.\n",
        "```\n",
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drGgRRpWf2Qm"
      },
      "source": [
        "# 使用稀疏张量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/guide/sparse_tensor\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a> </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/sparse_tensor_guide.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/sparse_tensor_guide.ipynb\">     <img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">     在 GitHub 上查看源代码</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/guide/sparse_tensor_guide.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIiXFIS4fj1m"
      },
      "source": [
        "使用包含大量零值的张量时，务必以节省空间和时间的方式存储它们。稀疏张量可以高效存储和处理包含大量零值的张量。稀疏张量广泛用于 [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) 等编码方案，作为 NLP 应用中数据预处理的一部分，以及在计算机视觉应用中预处理具有大量暗像素的图像。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8XXQW3ENU5m"
      },
      "source": [
        "## TensorFlow 中的稀疏张量\n",
        "\n",
        "TensorFlow 通过 `tf.sparse.SparseTensor` 对象表示稀疏张量。目前，TensorFlow 中的稀疏张量使用坐标列表 (COO) 格式进行编码。这种编码格式针对嵌入向量等超稀疏矩阵进行了优化。\n",
        "\n",
        "稀疏张量的 COO 编码包括：\n",
        "\n",
        "- `values`：形状为 `[N]` 的一维张量，包含所有非零值。\n",
        "- `indices`：形状为 `[N, rank]` 的二维张量，包含非零值的索引。\n",
        "- `dense_shape`：形状为 `[rank]` 的一维张量，指定张量的形状。\n",
        "\n",
        "`tf.sparse.SparseTensor` 上下文中的***非零***值是未显式编码的值。可以在 COO 稀疏矩阵的 `values` 中显式包含零值，但在稀疏张量中引用非零值时，通常不包含这些“显式零”。\n",
        "\n",
        "注：`tf.sparse.SparseTensor` 不要求索引/值按任何特定顺序排列，但一些运算假定它们按行优先顺序排列。使用 `tf.sparse.reorder` 创建按规范行优先顺序排序的稀疏张量副本。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Aq7ruwlyz79"
      },
      "source": [
        "## 创建 `tf.sparse.SparseTensor`\n",
        "\n",
        "通过直接指定它们的 `values`、`indices` 和 `dense_shape` 来构造稀疏张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from set_env import temp_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SI2Mv3tihcmY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vqQKGva4zSCs"
      },
      "outputs": [],
      "source": [
        "st1 = tf.sparse.SparseTensor(indices=[[0, 3], [2, 4]],\n",
        "                      values=[10, 20],\n",
        "                      dense_shape=[3, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9eJeh31fWyr"
      },
      "source": [
        "<img src=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/images/sparse_tensor.png?raw=true\" class=\"\">  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M3fMTFL0hXa"
      },
      "source": [
        "当您使用 `print()` 函数打印一个稀疏张量时，它会显示三个张量分量的内容："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3oHWtmsBMLAI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 3]\n",
            " [2 4]], shape=(2, 2), dtype=int64), values=tf.Tensor([10 20], shape=(2,), dtype=int32), dense_shape=tf.Tensor([ 3 10], shape=(2,), dtype=int64))\n"
          ]
        }
      ],
      "source": [
        "print(st1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqePKJG6MNWk"
      },
      "source": [
        "如果非零 `values` 与其对应的 `indices` 对齐，则更容易理解稀疏张量的内容。定义一个辅助函数来以美观的格式打印稀疏张量，以便每个非零值都显示在自己的行上。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R_xFYuOo1ZE_"
      },
      "outputs": [],
      "source": [
        "def pprint_sparse_tensor(st):\n",
        "  s = \"<SparseTensor shape=%s \\n values={\" % (st.dense_shape.numpy().tolist(),)\n",
        "  for (index, value) in zip(st.indices, st.values):\n",
        "    s += f\"\\n  %s: %s\" % (index.numpy().tolist(), value.numpy().tolist())\n",
        "  return s + \"}>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "be4Dyiqt0fEH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparseTensor shape=[3, 10] \n",
            " values={\n",
            "  [0, 3]: 10\n",
            "  [2, 4]: 20}>\n"
          ]
        }
      ],
      "source": [
        "print(pprint_sparse_tensor(st1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FBt8qk_zmz5"
      },
      "source": [
        "您还可以使用 `tf.sparse.from_dense` 从密集张量构造稀疏张量，并使用 `tf.sparse.to_dense` 将它们转换回密集张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cYwuCuNMf0Fu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparseTensor shape=[3, 4] \n",
            " values={\n",
            "  [0, 0]: 1\n",
            "  [0, 3]: 8\n",
            "  [2, 2]: 3}>\n"
          ]
        }
      ],
      "source": [
        "st2 = tf.sparse.from_dense([[1, 0, 0, 8], [0, 0, 0, 0], [0, 0, 3, 0]])\n",
        "print(pprint_sparse_tensor(st2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eFVPrwNPzyZw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 0 0 8]\n",
            " [0 0 0 0]\n",
            " [0 0 3 0]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "st3 = tf.sparse.to_dense(st2)\n",
        "print(st3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeuvyL_Z0Mwh"
      },
      "source": [
        "## 操纵稀疏张量\n",
        "\n",
        "使用 `tf.sparse` 软件包中的实用工具来操纵稀疏张量。像 `tf.math.add` 这样可用于密集张量的算术操纵的运算不适用于稀疏张量。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMYW4U4Qavvd"
      },
      "source": [
        "使用 `tf.sparse.add` 添加相同形状的稀疏张量。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vJwuSQIjayiN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparseTensor shape=[4, 10] \n",
            " values={\n",
            "  [0, 2]: 87\n",
            "  [3, 4]: 2\n",
            "  [7, 0]: 38}>\n"
          ]
        }
      ],
      "source": [
        "st_a = tf.sparse.SparseTensor(indices=[[0, 2], [3, 4]],\n",
        "                       values=[31, 2], \n",
        "                       dense_shape=[4, 10])\n",
        "\n",
        "st_b = tf.sparse.SparseTensor(indices=[[0, 2], [7, 0]],\n",
        "                       values=[56, 38],\n",
        "                       dense_shape=[4, 10])\n",
        "\n",
        "st_sum = tf.sparse.add(st_a, st_b)\n",
        "\n",
        "print(pprint_sparse_tensor(st_sum))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls8_aQvnqZMj"
      },
      "source": [
        "使用 `tf.sparse.sparse_dense_matmul` 将稀疏张量与密集矩阵相乘。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S0tWRLiE04uL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 78]\n",
            " [162]], shape=(2, 1), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "st_c = tf.sparse.SparseTensor(indices=([0, 1], [1, 0], [1, 1]),\n",
        "                       values=[13, 15, 17],\n",
        "                       dense_shape=(2,2))\n",
        "\n",
        "mb = tf.constant([[4], [6]])\n",
        "product = tf.sparse.sparse_dense_matmul(st_c, mb)\n",
        "\n",
        "print(product)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hxClYvfceZA"
      },
      "source": [
        "使用 `tf.sparse.concat` 将稀疏张量放在一起，使用 `tf.sparse.slice` 将它们分开。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cp4NEW_5yLEY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0]\n",
            " [0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]], shape=(8, 17), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "sparse_pattern_A = tf.sparse.SparseTensor(indices = [[2,4], [3,3], [3,4], [4,3], [4,4], [5,4]],\n",
        "                         values = [1,1,1,1,1,1],\n",
        "                         dense_shape = [8,5])\n",
        "sparse_pattern_B = tf.sparse.SparseTensor(indices = [[0,2], [1,1], [1,3], [2,0], [2,4], [2,5], [3,5], \n",
        "                                              [4,5], [5,0], [5,4], [5,5], [6,1], [6,3], [7,2]],\n",
        "                         values = [1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "                         dense_shape = [8,6])\n",
        "sparse_pattern_C = tf.sparse.SparseTensor(indices = [[3,0], [4,0]],\n",
        "                         values = [1,1],\n",
        "                         dense_shape = [8,6])\n",
        "\n",
        "sparse_patterns_list = [sparse_pattern_A, sparse_pattern_B, sparse_pattern_C]\n",
        "sparse_pattern = tf.sparse.concat(axis=1, sp_inputs=sparse_patterns_list)\n",
        "print(tf.sparse.to_dense(sparse_pattern))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XmE87XVPWPmc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 1]\n",
            " [0 0 0 1 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]], shape=(8, 5), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]], shape=(8, 1), dtype=int32)\n",
            "tf.Tensor([], shape=(8, 0), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "sparse_slice_A = tf.sparse.slice(sparse_pattern_A, start = [0,0], size = [8,5])\n",
        "sparse_slice_B = tf.sparse.slice(sparse_pattern_B, start = [0,5], size = [8,6])\n",
        "sparse_slice_C = tf.sparse.slice(sparse_pattern_C, start = [0,10], size = [8,6])\n",
        "print(tf.sparse.to_dense(sparse_slice_A))\n",
        "print(tf.sparse.to_dense(sparse_slice_B))\n",
        "print(tf.sparse.to_dense(sparse_slice_C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37SOx7wB1eSX"
      },
      "source": [
        "如果使用的是 TensorFlow 2.4 或更高版本，请使用 `tf.sparse.map_values` 对稀疏张量中的非零值执行逐元素运算。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "daZaPkkA1d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 6  0  0 13]\n",
            " [ 0  0  0  0]\n",
            " [ 0  0  8  0]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "st2_plus_5 = tf.sparse.map_values(tf.add, st2, 5)\n",
        "print(tf.sparse.to_dense(st2_plus_5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zkRcxeo2Elw"
      },
      "source": [
        "请注意，仅修改了非零值 – 零值保持为零。\n",
        "\n",
        "同样，可以遵循下方 TensorFlow 早期版本的设计模式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bFSNOOqC0ySb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 6  0  0 13]\n",
            " [ 0  0  0  0]\n",
            " [ 0  0  8  0]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "st2_plus_5 = tf.sparse.SparseTensor(\n",
        "    st2.indices,\n",
        "    st2.values + 5,\n",
        "    st2.dense_shape)\n",
        "print(tf.sparse.to_dense(st2_plus_5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFhO2ZZ53ga1"
      },
      "source": [
        "## 将 `tf.sparse.SparseTensor` 与其他 TensorFlow API 一起使用\n",
        "\n",
        "稀疏张量透明地与这些 TensorFlow API 一起使用：\n",
        "\n",
        "- `tf.keras`\n",
        "- `tf.data`\n",
        "- `tf.Train.Example` protobuf\n",
        "- `tf.function`\n",
        "- `tf.while_loop`\n",
        "- `tf.cond`\n",
        "- `tf.identity`\n",
        "- `tf.cast`\n",
        "- `tf.print`\n",
        "- `tf.saved_model`\n",
        "- `tf.io.serialize_sparse`\n",
        "- `tf.io.serialize_many_sparse`\n",
        "- `tf.io.deserialize_many_sparse`\n",
        "- `tf.math.abs`\n",
        "- `tf.math.negative`\n",
        "- `tf.math.sign`\n",
        "- `tf.math.square`\n",
        "- `tf.math.sqrt`\n",
        "- `tf.math.erf`\n",
        "- `tf.math.tanh`\n",
        "- `tf.math.bessel_i0e`\n",
        "- `tf.math.bessel_i1e`\n",
        "\n",
        "下面显示了上述 API 的一些示例。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uNUl7EgSYGC"
      },
      "source": [
        "### `tf.keras`\n",
        "\n",
        "`tf.keras` API 的一个子集支持稀疏张量，无需执行开销较大的类型转换或转换运算。可以利用 Keras API 将稀疏张量作为输入传递给 Keras 模型。调用 `tf.keras.Input` 或 `tf.keras.layers.InputLayer` 时设置 `sparse=True`。您可以在 Keras 层之间传递稀疏张量，也可以让 Keras 模型将它们作为输出返回。如果在模型中的 `tf.keras.layers.Dense` 层中使用稀疏张量，它们将输出密集张量。\n",
        "\n",
        "下面的示例展示了如果仅使用支持稀疏输入的层，如何将稀疏张量作为输入传递给 Keras 模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E8za5DK8vfo7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1729854472.678967 4109398 service.cc:146] XLA service 0x55fc4d6799b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1729854472.678997 4109398 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
            "I0000 00:00:1729854472.679001 4109398 service.cc:154]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows defined at (most recent call last):\n<stack traces unavailable>\nDetected at node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_567[] on XLA_GPU_JIT: SparseFillEmptyRows (No registered 'SparseFillEmptyRows' OpKernel for XLA_GPU_JIT devices compatible with node {{node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows}}){{node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows}}\nThe op is created at: \nFile \"<frozen runpy>\", line 198, in _run_module_as_main\nFile \"<frozen runpy>\", line 88, in _run_code\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/asyncio/events.py\", line 88, in _run\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\nFile \"/tmp/ipykernel_4109124/3652816815.py\", line 14, in <module>\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 901, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/models/functional.py\", line 175, in call\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/models/functional.py\", line 560, in call\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 901, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/layers/core/dense.py\", line 144, in call\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/numpy.py\", line 3445, in matmul\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 463, in matmul\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 425, in embedding_lookup_sparse_dense_matmul\n\ttf2xla conversion failed while converting __inference_one_step_on_data_567[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_574]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m sparse_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mSparseTensor(\n\u001b[1;32m      6\u001b[0m     indices \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      7\u001b[0m                (\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m),(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m0\u001b[39m),(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m)],\n\u001b[1;32m      8\u001b[0m     values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      9\u001b[0m     dense_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m model(sparse_data)\n\u001b[0;32m---> 14\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(sparse_data)\n",
            "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows defined at (most recent call last):\n<stack traces unavailable>\nDetected at node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_567[] on XLA_GPU_JIT: SparseFillEmptyRows (No registered 'SparseFillEmptyRows' OpKernel for XLA_GPU_JIT devices compatible with node {{node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows}}){{node functional_1/dense_1/SparseFillEmptyRows/SparseFillEmptyRows}}\nThe op is created at: \nFile \"<frozen runpy>\", line 198, in _run_module_as_main\nFile \"<frozen runpy>\", line 88, in _run_code\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/asyncio/events.py\", line 88, in _run\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\nFile \"/tmp/ipykernel_4109124/3652816815.py\", line 14, in <module>\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 198, in one_step_on_data\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 96, in predict_step\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 901, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/models/functional.py\", line 175, in call\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/models/functional.py\", line 560, in call\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 901, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/layers/core/dense.py\", line 144, in call\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/ops/numpy.py\", line 3445, in matmul\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 463, in matmul\nFile \"/media/pc/data/lxw/envs/anaconda3x/envs/xxx/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 425, in embedding_lookup_sparse_dense_matmul\n\ttf2xla conversion failed while converting __inference_one_step_on_data_567[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_574]"
          ]
        }
      ],
      "source": [
        "x = tf.keras.Input(shape=(4,), sparse=True)\n",
        "y = tf.keras.layers.Dense(4)(x)\n",
        "model = tf.keras.Model(x, y)\n",
        "\n",
        "sparse_data = tf.sparse.SparseTensor(\n",
        "    indices = [(0,0),(0,1),(0,2),\n",
        "               (4,3),(5,0),(5,1)],\n",
        "    values = [1,1,1,1,1,1],\n",
        "    dense_shape = (6,4)\n",
        ")\n",
        "\n",
        "model(sparse_data)\n",
        "\n",
        "model.predict(sparse_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtVYmr7dt0-x"
      },
      "source": [
        "### `tf.data`\n",
        "\n",
        "`tf.data` API 可用于通过简单的可重用代码段构建复杂的输入流水线。它的核心数据结构是 `tf.data.Dataset`，表示一系列元素，每个元素包含一个或多个分量。\n",
        "\n",
        "#### 使用稀疏张量构建数据集\n",
        "\n",
        "使用用于从 `tf.Tensor` 或 NumPy 数组构建数据集的相同方法从稀疏张量构建数据集，例如 `tf.data.Dataset.from_tensor_slices`。此运算保留了数据的稀疏性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3y9tiwuZ5oTD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [0]: 1\n",
            "  [1]: 1\n",
            "  [2]: 1}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [3]: 1}>\n",
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [0]: 1\n",
            "  [1]: 1}>\n"
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(sparse_data)\n",
        "for element in dataset: \n",
        "  print(pprint_sparse_tensor(element))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFaY5Org59qk"
      },
      "source": [
        "#### 批处理和取消批处理具有稀疏张量的数据集\n",
        "\n",
        "可以分别使用 `Dataset.batch` 和 `Dataset.unbatch` 方法批处理（将连续元素组合成单个元素）和取消批处理具有稀疏张量的数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WkKE0VY66Ii2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparseTensor shape=[2, 4] \n",
            " values={\n",
            "  [0, 0]: 1\n",
            "  [0, 1]: 1\n",
            "  [0, 2]: 1}>\n",
            "<SparseTensor shape=[2, 4] \n",
            " values={}>\n",
            "<SparseTensor shape=[2, 4] \n",
            " values={\n",
            "  [0, 3]: 1\n",
            "  [1, 0]: 1\n",
            "  [1, 1]: 1}>\n"
          ]
        }
      ],
      "source": [
        "batched_dataset = dataset.batch(2)\n",
        "for element in batched_dataset:\n",
        "  print (pprint_sparse_tensor(element))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ikZzPxl56bx1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [0]: 1\n",
            "  [1]: 1\n",
            "  [2]: 1}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [3]: 1}>\n",
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [0]: 1\n",
            "  [1]: 1}>\n"
          ]
        }
      ],
      "source": [
        "unbatched_dataset = batched_dataset.unbatch()\n",
        "for element in unbatched_dataset:\n",
        "  print (pprint_sparse_tensor(element))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ywfpD_EIMd3"
      },
      "source": [
        "还可以使用 `tf.data.experimental.dense_to_sparse_batch` 将不同形状的数据集元素批处理为稀疏张量。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB8QKh7p6ltl"
      },
      "source": [
        "#### 转换具有稀疏张量的数据集\n",
        "\n",
        "使用 `Dataset.map` 在数据集中转换和创建稀疏张量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E5lhicwef7Ah"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [0]: 2\n",
            "  [1]: 2\n",
            "  [2]: 2}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={}>\n",
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [3]: 2}>\n",
            "<SparseTensor shape=[4] \n",
            " values={\n",
            "  [0]: 2\n",
            "  [1]: 2}>\n"
          ]
        }
      ],
      "source": [
        "transform_dataset = dataset.map(lambda x: x*2)\n",
        "for i in transform_dataset:\n",
        "  print(pprint_sparse_tensor(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBfQvIVutp65"
      },
      "source": [
        "### tf.train.Example\n",
        "\n",
        "`tf.train.Example` 是 TensorFlow 数据的标准 protobuf 编码。将稀疏张量与 `tf.train.Example` 搭配使用时，您可以：\n",
        "\n",
        "- 使用 `tf.io.VarLenFeature` 将可变长度数据读入 `tf.sparse.SparseTensor`。但是，您应当考虑改用 `tf.io.RaggedFeature`。\n",
        "\n",
        "- 使用 `tf.io.SparseFeature` 将任意稀疏数据读入 `tf.sparse.SparseTensor`，它使用三个独立的特征键来存储 `indices`、`values` 和 `dense_shape`。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pir2Xt3nSe-4"
      },
      "source": [
        "### `tf.function`\n",
        "\n",
        "`tf.function` 装饰器为 Python 函数预先计算 TensorFlow 计算图，这样可以大幅提升 TensorFlow 代码的性能。稀疏张量能够透明地与 `tf.function` 和[具体函数](https://tensorflow.google.cn/guide/function#obtaining_concrete_functions)一起使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6jXDueTOSeYO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[225   0   0]\n",
            " [  0   0   0]\n",
            " [  0   0 625]], shape=(3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "@tf.function\n",
        "def f(x,y):\n",
        "  return tf.sparse.sparse_dense_matmul(x,y)\n",
        "\n",
        "a = tf.sparse.SparseTensor(indices=[[0, 3], [2, 4]],\n",
        "                    values=[15, 25],\n",
        "                    dense_shape=[3, 10])\n",
        "\n",
        "b = tf.sparse.to_dense(tf.sparse.transpose(a))\n",
        "\n",
        "c = f(a,b)\n",
        "\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPe5uC_X7XjZ"
      },
      "source": [
        "## 区分缺失值和零值\n",
        "\n",
        "`tf.sparse.SparseTensor` 上的大多数运算都以相同的方式处理缺失值和显式零值。这是特意这样设计的 – `tf.sparse.SparseTensor` 的行为应当像密集张量一样。\n",
        "\n",
        "但是，在少数情况下，区分零值和缺失值会十分有用。特别是，这样可以对训练数据中的缺失/未知数据进行编码。例如，考虑一个用例，其中包含一个分数张量（可以具有从 -Inf 到 +Inf 的任何浮点值），但缺少一些分数。可以使用稀疏张量对此张量进行编码，其中显式零是已知的零分数，但隐式零值实际上表示缺失数据，而不是零。\n",
        "\n",
        "注：这通常不是 `tf.sparse.SparseTensor` 的预期用途；并且您可能还想考虑其他技术来对此进行编码，例如使用单独的掩码张量来识别已知/未知值的位置。但是，在使用这种方式时要格外小心，因为大多数稀疏运算将以相同的方式处理显式和隐式零值。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ17F9e3ZJDS"
      },
      "source": [
        "请注意，像 `tf.sparse.reduce_max` 这样的一些运算不会将缺失值视为零。例如，运行下面的代码块时，预期输出为 `0`。但是，由于此异常，输出为 `-3`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kcNBVVtBZav_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(-3, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(tf.sparse.reduce_max(tf.sparse.from_dense([-5, 0, -3])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhzWLW-bMfI5"
      },
      "source": [
        "相反，当您将 `tf.math.reduce_max` 应用于密集张量时，输出如预期的那样为 0。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7Xy-g3VDNK9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(tf.math.reduce_max([-5, 0, -3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK3U8l0kNL37"
      },
      "source": [
        "## 补充阅读和资源\n",
        "\n",
        "- 请参阅[张量指南](https://tensorflow.google.cn/guide/tensor)来了解张量。\n",
        "- 阅读[不规则张量指南](https://tensorflow.google.cn/guide/ragged_tensor)以了解如何使用不规则张量，这是一种可以处理非均匀数据的张量。\n",
        "- 在 [TensorFlow Model Garden](https://github.com/tensorflow/models) 中查看此目标检测模型，此模型在 [`tf.Example` 数据解码器](https://github.com/tensorflow/models/blob/9139a7b90112562aec1d7e328593681bd410e1e7/research/object_detection/data_decoders/tf_example_decoder.py)中使用稀疏张量。\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sparse_tensor_guide.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "xxx",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
